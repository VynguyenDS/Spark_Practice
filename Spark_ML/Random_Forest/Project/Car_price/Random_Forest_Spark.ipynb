{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest_Spark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmmPFqlwwSOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b219c0c-06da-4d17-bbcf-880f44af2ec9"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "# !pip install pyspark\n",
        "from pyspark.sql  import SparkSession "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 65kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=e9c6d7b1f3e68356ea50271bff1fb2514ef727d23abdb01e625b8fd38ba9bee0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Ku2TS_wpXY"
      },
      "source": [
        "spark = (\n",
        "    SparkSession.builder.appName(\"Car_Price_Random_Forest\").getOrCreate()\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz5JipjbxE1V"
      },
      "source": [
        "car_price = (\n",
        "    spark.read.format(\"csv\")\n",
        "    .option(\"header\", True)\n",
        "    .load(\"CarPrice_Assignment.csv\")\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiqZIAjwxQMW"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "numeric_columns = [\"wheelbase\",\t\"carlength\",\t\"carwidth\",\t\"carheight\",\t\"curbweight\",\t\n",
        "                  \t\"enginesize\",\t\"boreratio\",\t\"stroke\",\t\"compressionratio\",\t\"horsepower\",\t\"peakrpm\",\t\"citympg\",\t\"highwaympg\",\"price\"]\n",
        "numeric_features = car_price.select([col(c).cast(\"float\") for c in numeric_columns])\n",
        "# car_price.describe().toPandas().transpose()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTkgEDmxgd5",
        "outputId": "9ff96ff3-e1e3-489e-845b-e093d6113e71"
      },
      "source": [
        "features = {}\n",
        "for i in numeric_columns:\n",
        "  features[i] = numeric_features.stat.corr(\"price\", i)\n",
        "  print(\"Correlation to Price for \", i , numeric_features.stat.corr(\"price\", i))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation to Price for  wheelbase 0.577815609013954\n",
            "Correlation to Price for  carlength 0.6829200061793368\n",
            "Correlation to Price for  carwidth 0.7593252732789826\n",
            "Correlation to Price for  carheight 0.11933627096290873\n",
            "Correlation to Price for  curbweight 0.8353048796203731\n",
            "Correlation to Price for  enginesize 0.8741448022848783\n",
            "Correlation to Price for  boreratio 0.5531732639743967\n",
            "Correlation to Price for  stroke 0.07944309329818429\n",
            "Correlation to Price for  compressionratio 0.06798351616221464\n",
            "Correlation to Price for  horsepower 0.8081388231007026\n",
            "Correlation to Price for  peakrpm -0.0852671497816066\n",
            "Correlation to Price for  citympg -0.6857513366309157\n",
            "Correlation to Price for  highwaympg -0.6975990921640883\n",
            "Correlation to Price for  price 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyVqWVouyMH8"
      },
      "source": [
        "# peakrpm , stroke \n",
        "features = set(numeric_features.columns) -set(['price', 'peakrpm', 'stroke' ])\n",
        "features = list(features)\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
        "car_price = vectorAssembler.transform(numeric_features)\n",
        "car_price = car_price.select([\"features\", \"price\"])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds-dCOTiyziO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3326acec-0140-4183-9871-f600edcd0ce8"
      },
      "source": [
        "from pyspark.ml.feature import Normalizer\n",
        "nomalizer = Normalizer(inputCol = \"features\", outputCol = \"normal_features\", p = 1.0)\n",
        "nomaizer_data = nomalizer.transform(car_price)\n",
        "nomaizer_data.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+--------------------+\n",
            "|            features|    price|     normal_features|\n",
            "+--------------------+---------+--------------------+\n",
            "|[64.0999984741211...|  13495.0|[0.01990825384693...|\n",
            "|[64.0999984741211...|  16500.0|[0.01990825384693...|\n",
            "|[65.5,9.0,2.68000...|  16500.0|[0.01835103999315...|\n",
            "|[66.1999969482421...|  13950.0|[0.02197809389148...|\n",
            "|[66.4000015258789...|  17450.0|[0.01884816198252...|\n",
            "|[66.3000030517578...|  15250.0|[0.02068520209184...|\n",
            "|[71.4000015258789...|  17710.0|[0.01999277613382...|\n",
            "|[71.4000015258789...|  18920.0|[0.01939537539296...|\n",
            "|[71.4000015258789...|  23875.0|[0.01863631300217...|\n",
            "|[67.9000015258789...|17859.168|[0.01791684408946...|\n",
            "|[64.8000030517578...|  16430.0|[0.02113916715578...|\n",
            "|[64.8000030517578...|  16925.0|[0.02113916715578...|\n",
            "|[64.8000030517578...|  20970.0|[0.01876406305937...|\n",
            "|[64.8000030517578...|  21105.0|[0.01846990602881...|\n",
            "|[66.9000015258789...|  24565.0|[0.01754795562038...|\n",
            "|[66.9000015258789...|  30760.0|[0.01637410333803...|\n",
            "|[67.9000015258789...|  41315.0|[0.01601596441157...|\n",
            "|[70.9000015258789...|  36880.0|[0.01619897585812...|\n",
            "|[60.2999992370605...|   5151.0|[0.02938009413829...|\n",
            "|[63.5999984741210...|   6295.0|[0.02550498616864...|\n",
            "+--------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AtR_EATzzxT"
      },
      "source": [
        "splits = nomaizer_data.randomSplit([0.8, 0.2])\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQo34KRkz6x0"
      },
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "dt  = DecisionTreeRegressor(featuresCol = \"normal_features\", labelCol  = \"price\")\n",
        "dt_model = dt.fit(train_df)\n",
        "dt_predictions = dt_model.transform(test_df)\n",
        "dt_evaluator = RegressionEvaluator(labelCol = \"price\", predictionCol = \"prediction\", metricName = \"rmse\")\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oO6E3Mv1DYe",
        "outputId": "99811dcc-f9ea-442d-ead8-1935d9096332"
      },
      "source": [
        "rmse = dt_evaluator.evaluate(dt_predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 3375.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WP_-5Eq1PUm",
        "outputId": "029dcf32-d0af-4b2a-a001-8d64fa1964e3"
      },
      "source": [
        "# It is Overfitting, So we must to use RandomForest Model and cross validation\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "dt_predictions = dt_model.transform(test_df)\n",
        "acc = dt_predictions.select(\"price\", \"prediction\").toPandas()\n",
        "print(\"Test_Accuracy\",r2_score(acc[\"price\"], acc[\"prediction\"]))\n",
        "dt_predictions.select(\"price\", \"prediction\").toPandas().info()\n",
        "dt_predictions = dt_model.transform(train_df)\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "dt_predictions = dt_model.transform(train_df)\n",
        "acc = dt_predictions.select(\"price\", \"prediction\").toPandas()\n",
        "r2_score(acc[\"price\"], acc[\"prediction\"])\n",
        "print(\"Train_Accuracy\", r2_score(acc[\"price\"], acc[\"prediction\"]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_Accuracy 0.7949995937090956\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38 entries, 0 to 37\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   price       38 non-null     float32\n",
            " 1   prediction  38 non-null     float64\n",
            "dtypes: float32(1), float64(1)\n",
            "memory usage: 584.0 bytes\n",
            "Train_Accuracy 0.9654387422638934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmyJ22Hc1aZz"
      },
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import Normalizer\n",
        "\n",
        "# peakrpm , stroke \n",
        "features = set(numeric_features.columns) -set(['price', 'peakrpm', 'stroke' ])\n",
        "features = list(features)\n",
        "\n",
        "vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
        "car_price = vectorAssembler.transform(numeric_features)\n",
        "# car_price = car_price.select([\"features\", \"price\"])\n",
        "\n",
        "nomalizer_model = Normalizer(inputCol = \"features\", outputCol = \"normal_features\", p = 1.0)\n",
        "\n",
        "random_forest = RandomForestRegressor(featuresCol=nomalizer_model.getOutputCol(), labelCol= \"price\")\n",
        "rfevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
        "\n",
        "pipeline = Pipeline(stages = [nomalizer_model, random_forest])\n",
        "paramGrid =  (\n",
        "    ParamGridBuilder()\n",
        "    # .addGrid(random_forest.maxDepth, [2, 5, 10])\n",
        "    .addGrid(random_forest.numTrees, [1000])\n",
        "    .build()\n",
        ")\n",
        "crossval = (\n",
        "    CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, numFolds=5,evaluator = rfevaluator)\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13-68dvB3Ayb"
      },
      "source": [
        "cvModel = crossval.fit(car_price)\n",
        "rfpredictions = cvModel.transform(test_df)\n",
        "rfpredictions.summary"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xXlF85pvTh"
      },
      "source": [
        "splits = car_price.randomSplit([0.8, 0.2])\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9vj6pCKsnBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80b124d-3900-4c9b-9806-165b06813483"
      },
      "source": [
        "rfpredictions = cvModel.transform(train_df)\n",
        "print('RMSE:', rfevaluator.evaluate(rfpredictions))\n",
        "acc = rfpredictions.select(\"price\", \"prediction\").toPandas()\n",
        "r2_score(acc[\"price\"], acc[\"prediction\"])\n",
        "print(\"Train Accuracy\", r2_score(acc[\"price\"], acc[\"prediction\"]))\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 1773.5091982853005\n",
            "Train Accuracy 0.9485340043534405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQjz7UKgvAr",
        "outputId": "b051f4ff-0fae-4826-fcb8-fb16c4f92b4c"
      },
      "source": [
        "rfpredictions = cvModel.transform(test_df)\n",
        "print('RMSE:', rfevaluator.evaluate(rfpredictions))\n",
        "acc = rfpredictions.select(\"price\", \"prediction\").toPandas()\n",
        "r2_score(acc[\"price\"], acc[\"prediction\"])\n",
        "print(\"Test_ Accuracy\", r2_score(acc[\"price\"], acc[\"prediction\"]))\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 1445.923093233406\n",
            "Test_ Accuracy 0.970199490102587\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}