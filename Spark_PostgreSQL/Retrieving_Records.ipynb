{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Spark_PostgreSQL\")\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.20.jar\")\n",
    "    .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Connect PostgreSQL with pySpark\")\n",
    "         .config(\"spark.jars\", \"postgresql-42.2.20.jar\")\n",
    "         .getOrCreate())\n",
    "# Read file\n",
    "emp_data = (spark\n",
    "  .read\n",
    "  .format(\"jdbc\") \n",
    "  .option(\"url\", \"jdbc:postgresql://localhost:5432/sqla\")\n",
    "  .option(\"dbtable\", \"emp\")\n",
    "  .option(\"user\", \"postgres\")\n",
    "  .option(\"password\", \"admin123\").option(\"driver\", \"org.postgresql.Driver\").load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data.createOrReplaceTempView(\"emp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+----+----------+-------+-------+------+\n",
      "|empno| ename|     job| mgr|  hiredate|    sal|   comm|deptno|\n",
      "+-----+------+--------+----+----------+-------+-------+------+\n",
      "| 7499| ALLEN|SALESMAN|7698|1981-02-20|1600.00| 300.00|    30|\n",
      "| 7521|  WARD|SALESMAN|7698|1981-02-22|1250.00| 500.00|    30|\n",
      "| 7654|MARTIN|SALESMAN|7698|1981-09-28|1250.00|1400.00|    30|\n",
      "| 7698| BLAKE| MANAGER|7839|1981-05-01|2850.00|   null|    30|\n",
      "| 7782| CLARK| MANAGER|7839|1981-06-09|2450.00|   null|    10|\n",
      "+-----+------+--------+----+----------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from emp limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+-------+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate|    sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+-------+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450.00|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000.00|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300.00|null|    10|\n",
      "+-----+------+---------+----+----------+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from emp \n",
    "    where deptno = 10\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "|empno| ename|      job| mgr|  hiredate|    sal|   comm|deptno|\n",
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600.00| 300.00|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250.00| 500.00|    30|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250.00|1400.00|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450.00|   null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000.00|   null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500.00|   0.00|    30|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300.00|   null|    10|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 880.00|   null|    20|\n",
      "| 7876| ADAMS|    CLERK|7788|1983-01-12|1210.00|   null|    20|\n",
      "+-----+------+---------+----+----------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the WHERE clause along with the OR and AND clauses. For example, if you would like to find all \n",
    "# the employees in department 10, along with any employees who earn a commission, along with any employees \n",
    "# in department 20 who earn at most $2000:\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select * \n",
    "    from emp\n",
    "    where deptno = 10 \n",
    "    or comm is not null \n",
    "    or sal <= 2000 and deptno = 20  \n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+\n",
      "| ename|deptno|    sal|\n",
      "+------+------+-------+\n",
      "| ALLEN|    30|1600.00|\n",
      "|  WARD|    30|1250.00|\n",
      "|MARTIN|    30|1250.00|\n",
      "| BLAKE|    30|2850.00|\n",
      "+------+------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You have a table and want to see values for specific columns rather than for all the columns.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename, deptno, sal\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show(n = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| salary|commission|\n",
      "+-------+----------+\n",
      "|1600.00|    300.00|\n",
      "|1250.00|    500.00|\n",
      "|1250.00|   1400.00|\n",
      "|2850.00|      null|\n",
      "|2450.00|      null|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To change the names of your query results use the AS keyword in the form: original_name AS new_name.\n",
    "# Some databases do not require AS, but all accept it:\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select sal as salary, comm as commission\n",
    "    from emp \n",
    "    \"\"\"\n",
    ").show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| salary|commission|\n",
      "+-------+----------+\n",
      "|1600.00|    300.00|\n",
      "|1250.00|    500.00|\n",
      "|1250.00|   1400.00|\n",
      "|2850.00|      null|\n",
      "|2450.00|      null|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You have used aliases to provide more meaningful column names for your result set and would like to \n",
    "# exclude some of the rows using the WHERE clause\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select * \n",
    "    from(\n",
    "    select sal as salary, comm as commission\n",
    "    from emp) x\n",
    "    where salary < 5000\n",
    "    \"\"\"\n",
    ").show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|concat(concat(ename, WORK AS A), job)|\n",
      "+-------------------------------------+\n",
      "|                 CLARKWORK AS AMAN...|\n",
      "|                 KINGWORK AS APRES...|\n",
      "|                 MILLERWORK AS ACLERK|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You want to return values in multiple columns as one column. For example, \n",
    "# you would like to produce this result set from a query against the EMP table:\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename || 'WORK AS A' || job\n",
    "    from emp\n",
    "    where deptno = 10\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---------+\n",
      "|   ename|    sal|   STATUS|\n",
      "+--------+-------+---------+\n",
      "|   ALLEN|1600.00|UNDERPAID|\n",
      "|    WARD|1250.00|UNDERPAID|\n",
      "|  MARTIN|1250.00|UNDERPAID|\n",
      "|   BLAKE|2850.00|       OK|\n",
      "|   CLARK|2450.00|       OK|\n",
      "|    KING|5000.00| OVERPAID|\n",
      "|  TURNER|1500.00|UNDERPAID|\n",
      "|   JAMES| 950.00|UNDERPAID|\n",
      "|  MILLER|1300.00|UNDERPAID|\n",
      "|Jonathan|   null|       OK|\n",
      "|   SMITH| 880.00|UNDERPAID|\n",
      "|   JONES|3272.50|       OK|\n",
      "|   SCOTT|3300.00|       OK|\n",
      "|   ADAMS|1210.00|UNDERPAID|\n",
      "|    FORD|3300.00|       OK|\n",
      "+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if an employee is paid $2000 or less, a message of “UNDERPAID” is returned\n",
    "#  if an employee is paid $4000 or more, a message of “OVERPAID” is returned, \n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename, sal, \n",
    "    case \n",
    "        when sal <= 2000 then 'UNDERPAID'\n",
    "        when sal >= 4000 then 'OVERPAID'\n",
    "    else 'OK'\n",
    "    end as STATUS\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+\n",
      "|coalesce(CAST(comm AS DECIMAL(12,2)), CAST(0 AS DECIMAL(12,2)))|\n",
      "+---------------------------------------------------------------+\n",
      "|                                                         300.00|\n",
      "|                                                         500.00|\n",
      "|                                                        1400.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "|                                                           0.00|\n",
      "+---------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You have rows that contain nulls and would like to return non-null values in place of those nulls.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select coalesce(comm, 0)\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "| ename|      job|\n",
      "+------+---------+\n",
      "| CLARK|  MANAGER|\n",
      "|  KING|PRESIDENT|\n",
      "|MILLER|    CLERK|\n",
      "| SMITH|    CLERK|\n",
      "| JONES|  MANAGER|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the LIKE operator in conjunction with the SQL wildcard operator (”%”):\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename, job\n",
    "    from emp \n",
    "    where deptno in (10, 20)\n",
    "    and (ename like '%I%' or job like \"%ER\")\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
