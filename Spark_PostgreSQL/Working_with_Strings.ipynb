{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Working with Strings\")\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.20.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database_to_read_file(database, table, user, password, name_file):\n",
    "    data = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/{}\".format(database))\n",
    "        .option(\"dbtable\", table)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").load()\n",
    "    )\n",
    "    return data.createOrReplaceTempView(name_file)\n",
    "emp_data = connect_database_to_read_file(\"sqla\", \"emp\", \"postgres\", \"admin123\", \"emp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = connect_database_to_read_file(\"sqla\", \"emp\", \"postgres\", \"admin123\", \"emp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_10 = connect_database_to_read_file(\"sqla\", \"t10\", \"postgres\", \"admin123\", \"t10\")\n",
    "t_1 = connect_database_to_read_file(\"sqla\", \"t1\", \"postgres\", \"admin123\", \"t1\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  C|\n",
      "+---+\n",
      "|  K|\n",
      "|  I|\n",
      "|  N|\n",
      "|  G|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select substr(e.ename,iter.pos,1) as C\n",
    "    from (select ename from emp where ename = 'KING') e,\n",
    "    (select id as pos from t10) iter\n",
    "    where iter.pos <= length(e.ename)\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|   A|   B|\n",
      "+----+----+\n",
      "|KING|   G|\n",
      "| ING|  NG|\n",
      "|  NG| ING|\n",
      "|   G|KING|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select substr(e.ename, iter.pos) as A,\n",
    "    substr(e.ename, length(e.ename) -iter.pos +1) as B\n",
    "    from (select ename from emp where ename = 'KING') e, (select id pos from t10) iter\n",
    "    where iter.pos <= length(e.ename)\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    qmarks|\n",
      "+----------+\n",
      "|g'day mate|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You want to embed quote marks within string literals.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select 'g' \"'\" 'day mate' qmarks from t1 \n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+\n",
      "| id| name|    job|\n",
      "+---+-----+-------+\n",
      "| 10|CLARK|MANAGER|\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select * from t1\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+---------+\n",
      "|   ename|  strip1|    sal|stripped2|\n",
      "+--------+--------+-------+---------+\n",
      "|   ALLEN|     LLN|1600.00|       16|\n",
      "|    WARD|     WRD|1250.00|      125|\n",
      "|  MARTIN|    MRTN|1250.00|      125|\n",
      "|   BLAKE|     BLK|2850.00|      285|\n",
      "|   CLARK|    CLRK|2450.00|      245|\n",
      "|    KING|     KNG|5000.00|        5|\n",
      "|  TURNER|    TRNR|1500.00|       15|\n",
      "|   JAMES|     JMS| 950.00|       95|\n",
      "|  MILLER|    MLLR|1300.00|       13|\n",
      "|Jonathan|Jonathan|   null|     null|\n",
      "|   SMITH|    SMTH| 880.00|       88|\n",
      "|   JONES|     JNS|3272.50|    32725|\n",
      "|   SCOTT|    SCTT|3300.00|       33|\n",
      "|   ADAMS|     DMS|1210.00|      121|\n",
      "|    FORD|     FRD|3300.00|       33|\n",
      "+--------+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You want to remove specific characters from your data.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename, \n",
    "    replace(translate(ename, 'UEOAI', '#'),'#', '') as strip1, \n",
    "    sal,\n",
    "    replace(translate(sal,'.0', '#'), '#','') as stripped2\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| ename|    sal|\n",
      "+------+-------+\n",
      "| ALLEN|1600.00|\n",
      "|  WARD|1250.00|\n",
      "|MARTIN|1250.00|\n",
      "| BLAKE|2850.00|\n",
      "| CLARK|2450.00|\n",
      "|  KING|5000.00|\n",
      "|TURNER|1500.00|\n",
      "| JAMES| 950.00|\n",
      "|MILLER|1300.00|\n",
      "|  null|   null|\n",
      "| SMITH| 880.00|\n",
      "| JONES|3272.50|\n",
      "| SCOTT|3300.00|\n",
      "| ADAMS|1210.00|\n",
      "|  FORD|3300.00|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select \n",
    "    replace(translate(data, \".0123456789\",'#'),'#','') as ename,\n",
    "    replace(data, replace(translate(data, \".0123456789\",'#'),'#',''), '') as sal\n",
    "    from\n",
    "    (\n",
    "        select ename || sal as data\n",
    "        from emp\n",
    "    )\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|full|\n",
      "+----+\n",
      "|S.G.|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select replace(\n",
    "           replace(\n",
    "           translate(replace('Stewie Griffin', '.', ''),\n",
    "                            'abcdefghijklmnopqrstuvwxyz',\n",
    "                            rpad('#',26,'#') ), '#','' ),' ','.' ) ||'.' as full\n",
    "    from t1\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   ename|\n",
      "+--------+\n",
      "|   ALLEN|\n",
      "|    WARD|\n",
      "|  MARTIN|\n",
      "|   BLAKE|\n",
      "|   CLARK|\n",
      "|    KING|\n",
      "|  TURNER|\n",
      "|   JAMES|\n",
      "|  MILLER|\n",
      "|Jonathan|\n",
      "|   SMITH|\n",
      "|   JONES|\n",
      "|   SCOTT|\n",
      "|   ADAMS|\n",
      "|    FORD|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|deptno|  collect_set(ename)|\n",
      "+------+--------------------+\n",
      "|  null|          [Jonathan]|\n",
      "|    10|[MILLER, KING, CL...|\n",
      "|    30|[MARTIN, BLAKE, J...|\n",
      "|    20|[SMITH, SCOTT, JO...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Delimited List from Table Rows\n",
    "# CREATE AGGREGATE textcat_all(\n",
    "#   basetype    = text,\n",
    "#   sfunc       = textcat,\n",
    "#   stype       = text,\n",
    "#   initcond    = ''\n",
    "# );\n",
    "\n",
    "# SELECT company_id, textcat_all(employee || ', ')\n",
    "# FROM mytable\n",
    "# GROUP BY company_id;\n",
    "from pyspark.sql import functions as F\n",
    "def connect_database_to_read_file(database, table, user, password, name_file):\n",
    "    data = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/{}\".format(database))\n",
    "        .option(\"dbtable\", table)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").load()\n",
    "    )\n",
    "    return data\n",
    "emp_data = connect_database_to_read_file(\"sqla\", \"emp\", \"postgres\", \"admin123\", \"emp\")\n",
    "emp_data.groupby(\"deptno\").agg(F.collect_set(\"ename\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [{'name', i} for i in range(len('7654,7698,7782,7788'))]\n",
    "\n",
    "data_df = spark.createDataFrame([i for i in range(100)], IntegerType(), ['number'])\n",
    "data_df.createOrReplaceTempView(\"t100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|value|       number_split|\n",
      "+-----+-------------------+\n",
      "|    0|7654,7698,7782,7788|\n",
      "|    1|7654,7698,7782,7788|\n",
      "|    2| 654,7698,7782,7788|\n",
      "|    3|  54,7698,7782,7788|\n",
      "|    4|   4,7698,7782,7788|\n",
      "|    5|    ,7698,7782,7788|\n",
      "|    6|     7698,7782,7788|\n",
      "|    7|      698,7782,7788|\n",
      "|    8|       98,7782,7788|\n",
      "|    9|        8,7782,7788|\n",
      "|   10|         ,7782,7788|\n",
      "|   11|          7782,7788|\n",
      "|   12|           782,7788|\n",
      "|   13|            82,7788|\n",
      "|   14|             2,7788|\n",
      "|   15|              ,7788|\n",
      "|   16|               7788|\n",
      "|   17|                788|\n",
      "|   18|                 88|\n",
      "|   19|                  8|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select t_100.value, substr('7654,7698,7782,7788',t_100.value) as number_split\n",
    "    from t1 as t_1,t100 as t_100\n",
    "    where t_100.value <= length('7654,7698,7782,7788')\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
