{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Working with Number\")\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.20.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database_to_read_file(database, table, user, password, name_file):\n",
    "    data = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/{}\".format(database))\n",
    "        .option(\"dbtable\", table)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").load()\n",
    "    )\n",
    "    return data.createOrReplaceTempView(name_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = connect_database_to_read_file(\"sqla\", \"emp\", \"postgres\", \"admin123\", \"emp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|    avg_sal|\n",
      "+-----------+\n",
      "|2007.500000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Problem:\n",
    "# You want to compute the avg value in column, either for all rows in a table or subset of rows\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select avg(coalesce(sal, 0)) as avg_sal\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|min_sal|max_sal|\n",
      "+-------+-------+\n",
      "| 880.00|5000.00|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When searching for the lowest and highest salaries for all employees, simply use the functions MIN and MAX\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select min(sal) as min_sal, max(sal) as max_sal\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+-------+-------+\n",
      "|coalesce(CAST(deptno AS DECIMAL(10,0)), CAST(0 AS DECIMAL(10,0)))|min_sal|max_sal|\n",
      "+-----------------------------------------------------------------+-------+-------+\n",
      "|                                                                0|   null|   null|\n",
      "|                                                               10|1300.00|5000.00|\n",
      "|                                                               30| 950.00|2850.00|\n",
      "|                                                               20| 880.00|3300.00|\n",
      "+-----------------------------------------------------------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When searching for the lowest and highest salaries for each department, \n",
    "# use the functions MIN and MAX with the GROUP BY \n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select coalesce(deptno, 0), min(sal) as min_sal, max(sal) as max_sal\n",
    "    from emp\n",
    "    group by deptno\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|deptno|total_for_dept|\n",
      "+------+--------------+\n",
      "|  null|          null|\n",
      "|    10|       8750.00|\n",
      "|    30|       9400.00|\n",
      "|    20|      11962.50|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You want to compute the sum of all values, such as all employee salaries, in a column.\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select deptno, sum(sal) as total_for_dept\n",
    "    from emp\n",
    "    group by deptno\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting Rows in a Table\n",
    "# You want to count the number of rows in a table, or you wish to count the number of values in a column\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(*)\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|deptno|count(1)|\n",
      "+------+--------+\n",
      "|  null|       1|\n",
      "|    10|       3|\n",
      "|    30|       6|\n",
      "|    20|       5|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select deptno, count(*)\n",
    "    from emp\n",
    "    group by deptno\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+------------+\n",
      "|count(1)|count(deptno)|count(comm)|count(hello)|\n",
      "+--------+-------------+-----------+------------+\n",
      "|      15|           14|          4|          15|\n",
      "+--------+-------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(*), count(deptno), count(comm), count('hello')\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(comm)|\n",
      "+-----------+\n",
      "|          4|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(comm)\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+\n",
      "|   ename|    sal|running_total|\n",
      "+--------+-------+-------------+\n",
      "|Jonathan|   null|         0.00|\n",
      "|   SMITH| 880.00|       880.00|\n",
      "|   JAMES| 950.00|      1830.00|\n",
      "|   ADAMS|1210.00|      3040.00|\n",
      "|    WARD|1250.00|      5540.00|\n",
      "|  MARTIN|1250.00|      5540.00|\n",
      "|  MILLER|1300.00|      6840.00|\n",
      "|  TURNER|1500.00|      8340.00|\n",
      "|   ALLEN|1600.00|      9940.00|\n",
      "|   CLARK|2450.00|     12390.00|\n",
      "|   BLAKE|2850.00|     15240.00|\n",
      "|   JONES|3272.50|     18512.50|\n",
      "|   SCOTT|3300.00|     25112.50|\n",
      "|    FORD|3300.00|     25112.50|\n",
      "|    KING|5000.00|     30112.50|\n",
      "+--------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# As an example, the following solutions show how to compute a running total of salaries for all employees\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ename,sal, sum(coalesce(sal,0)) over (order by sal) as running_total\n",
    "    from emp\n",
    "    order by 2\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|    sal|\n",
      "+-------+\n",
      "|3300.00|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem\n",
    "# You want to compute a running product on a numeric column.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select sal\n",
    "    from (\n",
    "        select sal as sal, count(*) as count\n",
    "        from emp \n",
    "        where deptno = 20\n",
    "        group by sal\n",
    "        having count(*)\n",
    "        order by count desc\n",
    "    ) x\n",
    "    limit 1\n",
    "    \"\"\" \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 pct|\n",
      "+--------------------+\n",
      "|29.05770029057700291|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem \n",
    "# Determining the Percentage of a Total\n",
    "# you want to determine what percentage of all salaries are the salaries in DEPTNO 10\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select ((sum(case when deptno = 10 then sal end) / sum(sal))*100) as pct\n",
    "    from emp\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
